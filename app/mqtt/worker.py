import json
import os
import sys
from datetime import datetime, timezone
from typing import Dict, Any, List
from multiprocessing import Queue
from queue import Empty
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from app.core.config import settings
from app.models.sensor import SensorReading
from app.core.logging import get_logger
from app.websocket.manager import WebSocketManager

logger = get_logger(__name__)

# å…¨å±€WebSocketå¹¿æ’­é˜Ÿåˆ—ï¼ˆç”¨äºè¿›ç¨‹é—´é€šä¿¡ï¼‰
websocket_broadcast_queue = None

def create_worker_db_session():
    """ä¸ºWorkerè¿›ç¨‹åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯"""
    engine = create_engine(
        settings.DATABASE_URL,
        pool_pre_ping=True,
        pool_recycle=300,
    )
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    return SessionLocal()

def parse_mqtt_message(payload: Any) -> Dict[str, Any]:
    """è§£æMQTTæ¶ˆæ¯"""
    try:
        data = payload.copy()
        
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        required_fields = ['sensor_id', 'value']
        for field in required_fields:
            if field not in data:
                raise ValueError(f"Missing required field: {field}")
        
        # å¤„ç†æ—¶é—´æˆ³
        if 'timestamp' in data:
            if isinstance(data['timestamp'], str):
                # å°è¯•è§£æISOæ ¼å¼æ—¶é—´æˆ³
                try:
                    data['timestamp'] = datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00'))
                except ValueError:
                    data['timestamp'] = datetime.now(timezone.utc)
            elif not isinstance(data['timestamp'], datetime):
                data['timestamp'] = datetime.now(timezone.utc)
        else:
            data['timestamp'] = datetime.now(timezone.utc)
        
        # ç¡®ä¿æ—¶é—´æˆ³æœ‰æ—¶åŒºä¿¡æ¯
        if data['timestamp'].tzinfo is None:
            data['timestamp'] = data['timestamp'].replace(tzinfo=timezone.utc)
        
        return data
        
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON format: {e}")
    except Exception as e:
        raise ValueError(f"Error parsing message: {e}")

def save_sensor_readings_batch(db: Session, readings: List[Dict[str, Any]]) -> int:
    """æ‰¹é‡ä¿å­˜ä¼ æ„Ÿå™¨è¯»æ•°åˆ°æ•°æ®åº“"""
    saved_count = 0
    
    try:
        sensor_objects = []
        
        for reading_data in readings:
            sensor_reading = SensorReading(
                sensor_id=reading_data['sensor_id'],
                timestamp=reading_data['timestamp'],
                value=float(reading_data['value']),
                unit=reading_data.get('unit'),
                location=reading_data.get('location'),
                meta=reading_data.get('meta', {})
            )
            sensor_objects.append(sensor_reading)
        
        # æ‰¹é‡æ’å…¥
        db.add_all(sensor_objects)
        db.commit()
        saved_count = len(sensor_objects)
        
        logger.info(f"âœ… Workerè¿›ç¨‹ä¿å­˜äº† {saved_count} æ¡ä¼ æ„Ÿå™¨æ•°æ®")
        
    except Exception as e:
        db.rollback()
        logger.error(f"âŒ æ‰¹é‡ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        
        # å°è¯•é€ä¸ªä¿å­˜
        for reading_data in readings:
            try:
                sensor_reading = SensorReading(
                    sensor_id=reading_data['sensor_id'],
                    timestamp=reading_data['timestamp'],
                    value=float(reading_data['value']),
                    unit=reading_data.get('unit'),
                    location=reading_data.get('location'),
                    meta=reading_data.get('meta', {})
                )
                db.add(sensor_reading)
                db.commit()
                saved_count += 1
                
            except Exception as individual_error:
                db.rollback()
                logger.error(f"âŒ ä¿å­˜å•æ¡æ•°æ®å¤±è´¥ {reading_data.get('sensor_id', 'unknown')}: {individual_error}")
    
    return saved_count

def dispatch(q: Queue, data: Dict[str, Any], raw: Dict[str, Any]):
    try:
        raw["created_at"] = datetime.now(timezone.utc).isoformat()
    except Exception as e:
        logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡º------------é”™: {e}")
        logger.error(f"-----{data}, -----{raw}-----")
        return
    q.put(raw)

def worker_process(task_queue: Queue, websocket_queue: Queue):
    """Workerè¿›ç¨‹ä¸»å‡½æ•°"""
    worker_id = os.getpid()
    logger.info(f"ğŸš€ Workerè¿›ç¨‹ {worker_id} å¯åŠ¨")
    
    # åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
    db = create_worker_db_session()
    
    try:
        while True:
            try:
                try:
                    msg = task_queue.get(timeout=5)
                except Empty:
                    continue
                
                # æ£€æŸ¥é€€å‡ºä¿¡å·
                if msg is None:
                    logger.warning(f"ğŸ”š Workerè¿›ç¨‹ {worker_id} æ”¶åˆ°é€€å‡ºä¿¡å·")
                    break
                
                try:
                    raw = json.loads(msg)
                    parsed = parse_mqtt_message(raw)
                    save_sensor_readings_batch(db, [parsed])
                    dispatch(websocket_queue, parsed.copy(), raw)
                except ValueError as e:
                    logger.error(f"âš ï¸ Worker {worker_id} æ¶ˆæ¯è§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.error(f"âŒ Worker {worker_id} å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    finally:
        db.close()
        logger.info(f"ğŸ”š Workerè¿›ç¨‹ {worker_id} å·²åœæ­¢")